# Principali linee di evoluzione architetturale

## Memoria cache e gerarchia di memoria
___

### Principio di funzionamento della memoria cache

La memoria cache e' stata introdotta per ottimizzare le prestazioni della memoria di lavoro.
Inizialmente la velocita' della memoria di lavoro DRAM e della CPU erano dello stesso ordine di grandezza, ma partire dagli anni 80 la frequenza di lavoro delle CPU Intel i86 crebbe molto velocemente. Verso la fine degli anni 90 il gap e' gia' di ordine 10.
Come e' possibile che i PC funzionassero (e funzionino) con una memoria di lavoro 10 volte piu' lenta della CPU? Se ogni volta che la CPU deve esegure il fetch dobbiamo attendere 10 giri di clock per accedere a memoria c'e' qualcosa che non torna...

Se plottiamo il grafico tempo-indirizzi di memoria a cui la CPU accede, notiamo come, tranne in casi isolati, siano presenti delle "zone calde", ossia gruppi di celle di memoria non necessariamente contigue, ma comunque vicine che vengono interrogate in sequenza, seguendo dei "pattern regolari".

Questo fenomeno prende il nome di **principio di localita'** degli accessi a memoria da parte della CPU:
> Se all'istante t la CPU genera l'indirizzo di memoria xNNNN, e' molto probabile che nell'immediato futuro generi di nuovo lo stesso indirizzo xNNNN o indirizzi vicini (**locali**) all'indirizzo xNNNN.

Ci sono 2 motivazioni per cui questo fenomeno avviene:
* Localita' **spaziale**:
  * Il fetch delle istruzioni procede normalmente in celle consecutive;
  * I programmi sono organizzati in blocchi, moduli, procedure, e le variabili del singolo blocco sono memorizzate in spazi di memoria vicini;
* Localita' **temporale**:
  * L'essenza della programmazione sono i **cicli**, l'esistenza di gruppi di istruzioni scritte una volta ed eseguite molte volte dal calcolatore. Quindi le istruzioni e le variabili scritte nei cicli vengono reiterate molte volte.

Quando la CPU genera un indirizzo di memoria portiamo il contenuto della cella rischiesta e un certo numero di celle vicine **blocco** in una memoria (a lettura  e scrittura):
* Piu' veloce della DRAM;
* Ovviamente piu' piccola perche piu' costosa da realizzare.

Questa memoria prende il nome di **cache**, in derivazione dalla parola francese *casche'* (nascosto) perche' la sua esistenza non e' nota ne' al programmatore ne' alla CPU (la CPU genera indirizzi di memoria di lavoro, pensati per la DRAM). La cache serve a sfruttare statisticamente il fatto che di tutte le celle della memoria di lavoro, solo un sottoinsime e' di piu' probabile utilizzo da parte della CPU, quindi di fatto la sua presenza serve solo a velocizzare gli accessi a memoria.

Intel era solita far uscire ogni 4 anni una nuova generazione di processori.
Durante l'arco di vita del processore, il numero di MIPS massimi tendeva a raddoppiare (miglioramento **tecnologico**).
Mentre tra una generazione e l'altra vediamo una triplicazione del numero di transistor che genera complessita' (miglioramento **architetturale**).

I transistor in piu' a partire dall'82 vennero impiegati per realizzare una memoria cache **a bordo** del chip della CPU in modo che possa lavorare alla stessa frequenza di clock: nacque quindi la **cache L1** (di primo livello) di qualche KB.
La frequenza del processore pero' e' cresciuta a tal punto che la differenze con la DRAM sono diventate sempre piu' evidenti.
Venne introdotta la **cache L2** (di secondo livello), stavolta **esterna** al processore di qualche centinaio di KB, tipicamente di tipo SRAM.
In casi limite viene impiegata anche una **cache L3** (di terzo livello), sempre esterna al processore, di qualche decina di MB.

___

### Memoria cache e politica Tag Associative

La cache e' contenitore di una copia dei blocchi di celle di memoria di lavoro che circondano la cella richiesta dalla CPU in un dato accesso alla memoria.
Il progetto della cache richiede una struttura generale:
* Memoria di lavoro divisa in blocchi di dimensione predefinita (ad esempio 16 celle o parole), ma che non puo' essere troppo elevata altrimenti incappiamo in rallentamenti eccessivi durante il processo di copia;
* Memoria cache divisa in blocchi di dimensione uguale a quelli della memoria di lavoro;
* Ogni volta che non e' presente una cella indirizzata dalla CPU nella memoria cache, si trasporta all'interno della cache l'interno blocco di memoria di lavoro che la contiene.

Abbiamo pero' 3 problemi da risolvere:
* Mapping dei blocchi da memoria di lavoro a memoria cache: ogni blocco di memoria di lavoro in quale o quali blocchi di memoria cache puo' essere copiato;
* Ricerca della parola richiesta dalla CPU: quando la CPU genera un indirizzo di memoria dobbiamo verificare se la parola richiesta si trova in cache:
  * In caso positivo si parla di **HIT**;
  * In caso negativo si parla di **MISS**, dunque la parola cercata deve essere prelevata dalla memoria di lavoro rallentando notevolmente l'esecuzione;
* Sostituzione del blocco di memoria cache in caso di MISS: quali azioni si devono intraprendere per ottimizzare l'uso della cache (fare in modo che l'**HIT-RATIO** sia il piu' alto possibile).

#### Mapping dei blocchi da memoria di lavoro a memoria cache
Vediamo dunque come funziona la politica **Tag Associative** e per farlo facciamo riferimento alla memoria di lavoro della CPU LC-2 costituita da 64K parole.
Supponiamo di dimensionare il blocco trasferibile su memoria cache a 16 parole, questo fa si che l'intera memoria di lavoro sia divisa in 4096 blocchi da 16 parole ciascuno.
Supponiamo poi di avere una memoria cache costituita da 128 blocchi da 16 parole ciascuno.
Nella polita Tag Associative si crea una corrispondenza univoca tra blocchi di memoria di lavoro e blocchi di memoria cache: un blocco di memoria di lavoro puo' essere copiato in uno e un solo blocco di memoria cache. Poiche' il numero di blocchi della memoria di lavoro e' molto superiore, abbiamo un rapporto **many-to-one** in quanto piu' blocchi di memoria di lavoro sono connessi ad un singolo blocco di cache. Ogni blocco di memoria cache e' connesso ad un **gruppo** di blocchi di memoria di lavoro.

Possiamo etichettare il singolo blocco di memoria di lavoro, suddividere il suo indirizzo (da 0 a 4095) in 2 parti:
* Una che ci dice in che posizione del blocco di memoria cache si trova rispetto al gruppo;
* Una che ci dice di quale gruppo di memoria di lavoro fa parte.

In qualsiasi istante avremo in cache una copia di alcuni blocchi di memoria di lavoro e ci e' facile intuire a quale gruppo fa riferimento un determinato blocco di memoria cache. Per ricordarci invece quale blocco di memoria di lavoro (rispetto al gruppo) si trova in cache segnamo il numero del blocco di memoria di lavoro in una memoria di **tag**.
Variando il contenuto della memoria di tag teniamo traccia di quale blocco dei vari gruppi sono istante per istante presenti nella cache.

Dunque nella politica Tag Associative si definisce a priori una corrispondenza univoca tra:
* gruppo di blocchi in memoria di lavoro;
* blocco di possibile destinazione della cache.

L'indirizzo generato dalla CPU (a 16bit) ha la seguente struttura (partendo dai bit meno significativi):
* **NP: Numero di parola nel blocco** - 4bit (2^4=16 parole per blocco di memoria di lavoro);
* **NG: Numero del gruppo di blocchi** - 7bit (2^7=128 gruppi di memoria di lavoro / blocchi di cache);
* **NB: Numero del blocco nel gruppo** - 5bit (2^5=32 blocchi per gruppo di memoria di lavoro).

#### Ricerca della parola richiesta dalla CPU e sostituzione del blocco di memoria cache in caso di MISS

Sull'Address Bus, la CPU indirizza una cella concatenando NB & NG & NP.
Per scoprire se NB e' presente in cache andiamo a leggere nella tabella dei tag in posizione NG se NB e' caricato:
* HIT: la CPU interagisce con la cella di memoria cache di indirizzo NG & NP;
* MISS: 
  * Preleviamo da memoria di lavoro il blocco necessario di indirizzo NB & NG e lo copiamo nel blocco di cache di indirizzo NG;
  * Il tag associato al gruppo NG viene aggiornato con il valore NB;
  * La CPU ora puo' interagire con la memoria cache di indirizzo NG & NP (come nel caso di HIT).

La differenza e' in termini di tempo, perche' sono necessarie 2 operazioni preliminari nel caso di MISS.

Caratteristiche del Tag Associative:
* **Politica semplice**: il blocco richiesto dalla CPU puo' trovarsi solo in un blocco di cache
  * la scoperta di HIT/MISS e' rapida e priva di problemi (basta leggere il contenuto dell'unico blocco di cache, indicato dal tag NG, che puo' contenere il blocco di memoria di lavoro);
  * In caso di MISS il blocco richiesto puo' essere ricopiato in un'unica posizione;
* **Politica non ottimizzata**: ogni blocco di memoria cache **ottimizza localmente** l'accessibilita' ai blocchi di memoria di lavoro assegnati (solo il blocco di memoria di lavoro piu' recente e' tenuto in cache rispetto al suo gruppo)
  * Se due blocchi di memoria di lavoro facenti parte dello stesso gruppo sono piu' gettonati (anche e soprattutto rispetto altri blocchi di memoria di lavoro di altri gruppi), lo sfruttamento dei blocchi di memoria cache non e' uniforme.

___

### Politiche Fully Associative e Set Associative

La politica Tag Associative e' semplice da realizzare ma non ottimizza l'uso della memoria cache: il problema principale sta nell'**allocazione fissa** fra i blocchi di memoria di lavoro e memoria cache.

#### Mapping della politica Fully Associative

La politica Fully Associative prevede un accoppiamento libero: qualsiasi blocco di memoria di lavoro puo' essere copiato in qualsiasi blocco di cache.
Dunque sparisce il concetto di gruppo, di riflesso il tag aumenta di dimensioni.

La struttura dell'indirizzo generato dalla CPU e' diversa (partendo dal bit meno significativo):
* **NP: Numero di parola nel blocco** - 4bit (2^4=16 parole per blocco di memoria di lavoro);
* **NBMdl: Numero del blocco in memoria di lavoro** - 12bit (2^12=4096 blocchi di memoria di lavoro).

Servono pero' ulteriori elementi circuitali di una certa complessita'.

Per poter verificare rapidamente se il blocco richiesto e' in cache:
* La memoria dei tag deve essere una memoria ad **accesso associativo**:
  * Devo far vedere alla memoria di tag a quale numero di blocco di memoria di lavoro sono interessato;
  * Ottenere in un tempo di accesso l'indirizzo della cella che lo contiene e quindi il blocco di cache nel quale e' copiato il blocco di memoria di lavoro che cerco (oppure una segnalazione di assenza).

Per poter decidere dove scrivere il blocco cercato se non e' presente in cache (MISS):
* Facciamo uso della politica **LRU** (Least Recently Used) ossia sovrascriviamo il blocco di cache "piu' vecchio" con il blocco di memoria che ci serve;
  * Per sapere quale e' il blocco LRU si associa ad ogni blocco di cache un **contatore a saturazione**:
    * Viene azzerato quando si accede al blocco associato;
    * Incrementato di 1 quando si accede ad un altro blocco;
  * Se questi contatori, come valore di fine scala hanno il numero di blocchi di cache (nel nostro caso 128), si e' sicuri di avere sempre un contatore saturo (che contiene 11..11), ossia un blocco che da almeno 128 volte non e' stato utilizzato.

#### Ricerca parola in cache con politica Fully Associative

La CPU genera sull'Address Bus l'indirizzo composto dalla concatenazione NBMdl & NP.
Il gestore di cache fa un accesso associativo alla memoria di tag specificando NBMdl come contenuto del registro associativo e ottiene come risultato il numero di blocco in memoria cache il blocco di memoria di lavoro cercato:
* HIT: 
  * La CPU interagisce con la cella di memoria indicata dal numero di blocco di memoria cache & NP;
  * Aumentiamo di 1 tutti i contatori a saturazione;
  * Azzeriamo il contatore del blocco di cache indirizzato.
* MISS:
  * Identifichiamo in quale blocco di memoria cache effettuare la ricopiatura facendo un accesso associativo ai contatori a saturazione cercando il primo di essi che contiene tutti uni (11..11) in modo da trovare il blocco LRU;
  * Effettuiamo la copiatura dal blocco di memoria (NBMdl dato dalla CPU in ingresso) di lavoro al blocco di cache LRU;
  * Scriviamo l'identificativo NBMdl nei tag per tenere traccia del contenuto del blocco di cache;
  * Consentiamo alla CPU di fare l'accesso alla memoria cache (da qui in poi come nel caso di HIT);
  * Aumentiamo di 1 tutti i contatori a saturazione;
  * Azzeriamo il contatore del blocco di cache indirizzato.

Caratteristiche Fully Associative:
* **Politica ottimizzata**: i blocchi presenti in cache sono sempre quelli che nel recente passato sono stati piu' richiesti dalla CPU
  * Otteniamo uno sfruttamento omogeneo dei blocchi di cache;
* **Politica complessa e costosa**: la ricerca del blocco richiesto implica il ricorso a memoria associativa per i tag
  * Per implementare la politica LRU serve prevedere l'uso dei contatori a saturazione che devono anche essi essere accessibili in modo asssociativo.

#### Politica Set Associative

Compromessi:
* Un blocco di memoria di lavoro puo' essere copiato in un **insieme limitato (set)** di blocchi di cache:
  * Si parla di **n-way cache Set Associative**:
    * Con vari valori di n che concidono con il numero di blocchi cache dove puo' essere copiato un blocco di memoria di lavoro (un singolo blocco di memoria di lavoro puo' essere copiato in n blocchi cache).
* Semplifica la progettazione circuitale ma non e' perfettamente omogeneo come la politica Fully Associative.